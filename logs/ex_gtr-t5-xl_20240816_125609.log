INFO:root:
---DATASET PATH---:
example_data/subsampled_crag_task_1_dev_v3_release.jsonl.bz2
INFO:root:
---MODELS/USER_CONFIG.PY FILE---:
# from models.dummy_model import DummyModel
# isort: skip_file

# UserModel = DummyModel

# Uncomment the lines below to use the Vanilla LLAMA baseline
# from models.vanilla_llama_baseline import InstructModel

# UserModel = InstructModel


# Uncomment the lines below to use the RAG LLAMA baseline
from generation.chatmodel import RAGModel

UserModel = RAGModel

INFO:root:
---CONFIG PATH---:
config/reranking_before_top_k_15.yaml
INFO:root:
---CONFIGS---:
ChatModelParams:
  MODEL_PATH: models/meta-llama/Meta-Llama-3-70B-Instruct
  VLLM_TENSOR_PARALLEL_SIZE: 4
  VLLM_GPU_MEMORY_UTILIZATION: 0.5
  N_OUT_SEQ: 1
  TOP_P: 0.9
  TEMPERATURE: 0.1
  SKIP_SPECIAL_TOKENS: true
  MAX_TOKENS: 50
EmbeddingModelParams:
  MODEL_PATH: models/sentence-transformers/gtr-t5-xl
  SENTENTENCE_TRANSFORMER_BATCH_SIZE: 128
  RERANKING_MODEL_PATH: models/sentence-transformers/BAAI/bge-reranker-v2-m3
  TOP_K_BEFORE_RERANKING: 15
RagSystemParams:
  NUM_CONTEXT_SENTENCES: 15
  MAX_CONTEXT_SENTENCE_LENGTH: 2048
  MAX_CONTEXT_REFERENCES_LENGTH: 32000
  AICROWD_SUBMISSION_BATCH_SIZE: 8
  TOP_K_BEFORE_RERANKING: 15
EvaluationModelParams:
  MODEL_PATH: models/meta-llama/Meta-Llama-3-70B-Instruct

INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: models/sentence-transformers/gtr-t5-xl
INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: cuda
INFO:root:
---EVALUATION RESULTS---:
score: 0.0930930930930931
exact_accuracy: 0.0960960960960961
accuracy: 0.32432432432432434
hallucination: 0.23123123123123124
missing: 0.4444444444444444
n_miss: 148
n_correct: 108
n_correct_exact: 32
total: 333

INFO:root:
 ---EXPERIMENT DURATION---
batch_generate_answer: 15.33 Min
calculate_embeddings: 3.37 Min
evaluate_predictions: 2.50 Min
generate_prediction: 15.62 Min
get_reranking_scores: 0.33 Min
total_duration: 23.67 Min

